{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning an XGBoost Model\n",
    "\n",
    "Using the same CV procedures as the other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Functions\n",
    "\n",
    "Copying over metrics and CV functions from `cross_val.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METRICS \n",
    "\n",
    "def classification_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    computes conf matrix + acc, prec, rec, and f1\n",
    "    \n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "\n",
    "    # conf matrix\n",
    "    tp = np.sum((y_true==1) & (y_pred==1))\n",
    "    tn = np.sum((y_true==0) & (y_pred==0))\n",
    "    fp = np.sum((y_true==0) & (y_pred==1))\n",
    "    fn = np.sum((y_true==1) & (y_pred==0))\n",
    "\n",
    "    acc  = (tp + tn) / max((tp + tn + fp + fn), 1)\n",
    "    prec = tp / max((tp + fp), 1)\n",
    "    rec  = tp / max((tp + fn), 1)\n",
    "    f1   = (2*prec*rec / max((prec+rec), 1e-12)) if (prec+rec)>0 else 0.0\n",
    "\n",
    "    metrics = {\n",
    "        \"tp\":tp, \"tn\": tn, \"fp\":fp, \"fn\":fn, \"acc\":acc, \"prec\":prec, \"rec\": rec, \"f1\":f1\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def roc_auc_from_probs(y_true, y_prob):\n",
    "    \n",
    "    desc_sort_indices = np.argsort(-y_prob)\n",
    "    y_true = np.array(y_true)[desc_sort_indices]\n",
    "    y_prob = np.array(y_prob)[desc_sort_indices]\n",
    "    pos = np.sum(y_true == 1)\n",
    "    neg = np.sum(y_true == 0)\n",
    "\n",
    "    # running totals for TPR/FPR\n",
    "    tpr = [0.0]\n",
    "    fpr = [0.0]\n",
    "    tp = fp = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == 1:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "        tpr.append(tp / pos)\n",
    "        fpr.append(fp / neg)\n",
    "\n",
    "    # get auc\n",
    "    auc = np.trapz(tpr, fpr)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_index_split_random(n, k, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = np.arange(n)\n",
    "    rng.shuffle(idx)\n",
    "    folds = np.array_split(idx, k)\n",
    "    return [\n",
    "        (np.concatenate(folds[:i] + folds[i+1:]), folds[i])\n",
    "        for i in range(k)\n",
    "    ]\n",
    "\n",
    "def train_test_index_split_stratified(y, k, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y = np.asarray(y)\n",
    "    folds = [[] for _ in range(k)]\n",
    "    # distribute classes evenly across folds\n",
    "    for cls in np.unique(y):\n",
    "        indexes = rng.permutation(np.where(y == cls)[0])\n",
    "        split = np.array_split(indexes, k)\n",
    "        for i in range(k):\n",
    "            folds[i].extend(split[i])\n",
    "    splits = []\n",
    "    for i in range(k):\n",
    "        test_idx = np.array(folds[i])\n",
    "        train_idx = np.concatenate([folds[j] for j in range(k) if j != i])\n",
    "        splits.append((train_idx, test_idx))\n",
    "    return splits\n",
    "\n",
    "def cross_validate(X, y, k=5, split=\"stratified\", seed=42, model_fn=None):\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    # split method\n",
    "    if split == \"stratified\":\n",
    "        splits = train_test_index_split_stratified(y, k, seed)\n",
    "    elif split == \"random\":\n",
    "        splits = train_test_index_split_random(len(y), k, seed)\n",
    "    elif split == \"nonrandom\":\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"split type not found\")\n",
    "\n",
    "    results = []\n",
    "    for fold, (train_idx, test_idx) in enumerate(splits, 1):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        if model_fn is None:\n",
    "            results.append({\n",
    "                \"fold\": fold,\n",
    "                \"train_idx\": train_idx, \"test_idx\": test_idx,\n",
    "                \"X_train\": X_train, \"y_train\": y_train,\n",
    "                \"X_test\": X_test, \"y_test\": y_test,\n",
    "            })\n",
    "        else:\n",
    "            # TODO: create model_fn for our four methods\n",
    "            metrics = model_fn(X_train, y_train, X_test, y_test)  \n",
    "            metrics[\"fold\"] = fold\n",
    "            results.append(metrics)\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
